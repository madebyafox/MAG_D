---
title: "Visualization Attitudes via Repertory Grid"
author: "Amy R Fox & Dana Hua"
date: "2024-05-01"
output:
  html_document:
    theme: cosmo
    code_folding: hide
    fig_caption: yes
    number_sections: no
    toc: yes
    toc_float:
      collapsed: yes
      smooth_scroll: yes
    toc_depth: 6
  pdf_document:
    toc: yes
    toc_depth: '5'
always_allow_html: yes
font-family: DejaVu Sans
mainfont: DejaVu Sans
editor_options: 
  markdown: 
    wrap: 72
---


# SETUP

### Import Packages

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)

#UTILITIES
library(Hmisc) # %nin% operator
library(psych) #describe() & efa
library(tidyverse) #all the things
library(magrittr) #special pipes like %<>%
library(summarytools) #data quality
library(lubridate) #dealing with dates


#VIZ
library(ggformula) #regression syntax viz
library(ggstatsplot) #dummies
library(gghalves) #half boxplots 
library(GGally) #extends ggplot for EDA 
library(corrplot) #sophisticated correlation plots
library(ggeasy) #easy labelling
library(ggh4x) #guides [dual axes]
library(patchwork) #multi-plot layout
library(ggdist) #raincloud plots and other distributionals
library(viridis) #color palettes
library(RColorBrewer) #color palettes
library(plotly) # interactive graphs
library(paletteer) #more palettes
library(interactions) ##easier regression ixn plots.srlsy
library(tidygraph)

#TABLES
library(gt)
library(qacBase)
library(openxlsx)

#REP GRID ANALYSIS
library(OpenRepGrid) #https://docs.openrepgrid.org/index.html
library(ggfortify) #autoplot for prcomp

#MODELLING
# library(jtools) #Social Science regression utilities
library(easystats) #modelling helpers
library(see)
library(sjPlot)
library(lme4)
library(lmerTest) #for CIs in glmer
# # library(mixed) ## utilities for glmers 
# library(jmv) ## jamovi EFA


#STATISTICAL TESTS 
# library(kSamples) #AD K-SAMPLE TEST (for distribution comparison)
# library(rstatix) #FRIEDMAN'S TESTS and effect sizes 

#CONFIG
options(readr.show_col_types = FALSE) #don't show coltypes on read_csv


## IMPORTANT 
# GRAPH_SAVE = TRUE #set to true to generate all the SD graphs and save to folders 
# source("graphing_functions.R") #import graphing palettes and custom functions

```

### Import Data
```{r import-data}

#example grids from package
# bell2010
# mackay1992
# fbb2003

## IMPORT CLEAN PARTICIPANT-LEVEL GRIDS
## load grid (continuous constructs only) for each participant 
## #importExcel from OpenRepGrid package, creates S4 object 
p4 <-  importExcel(file= "data/participant_grids/simple/P04_clean.xlsx") # researcher
p5 <-  importExcel(file= "data/participant_grids/simple/P05_clean.xlsx") # researcher
p6 <-  importExcel(file= "data/participant_grids/simple/P06_clean.xlsx") # researcher
p7 <-  importExcel(file= "data/participant_grids/simple/P07_clean.xlsx") # researcher
p15 <- importExcel(file= "data/participant_grids/simple/P15_clean.xlsx") # researcher 


p8 <-  importExcel(file= "data/participant_grids/simple/P08_clean.xlsx") # designer
p9 <-  importExcel(file= "data/participant_grids/simple/P09_clean.xlsx") # designer
p10 <- importExcel(file= "data/participant_grids/simple/P10_clean.xlsx") # designer
p11 <- importExcel(file= "data/participant_grids/simple/P11_clean.xlsx") # designer
p12 <- importExcel(file= "data/participant_grids/simple/P12_clean.xlsx") # designer
p13 <- importExcel(file= "data/participant_grids/simple/P13_clean.xlsx") # designer
p14 <- importExcel(file= "data/participant_grids/simple/P14_clean.xlsx") # designer 

## IMPORT RAW CODED-DATA DATAFRAME
## row = one participant construct (elements as cols)
df_raw <- read_csv(file = "data/CODED_CONSTRUCTS.csv",  na=c("", "NA"))

```

### Wrangle Data
```{r wrangle}


names <- c("RESEARCHER P4","RESEARCHER P5","RESEARCHER P6","RESEARCHER P7","RESEARCHER P15","DESIGNER P8","DESIGNER P9","DESIGNER P10","DESIGNER P11","DESIGNER P12","DESIGNER P13","DESIGNER P14")

stimuli <- c("CAREBEAR_BARS","LADY_LINE","BULLET_BARS","CARTOMAP","MAN_INFO","PENGUIN_DISTS","HISTO_DIST",	"IXN_EBARS","IXN_SLOPE","BAYES_RIDGES")



## CREATE GROUP-LEVEL GRIDS
g_researchers <- p4 + p5 + p6 + p7 + p15
g_designers <- p8 + p9 + p10 + p11 + p12 + p13 + p14

## CREATE MASTER GRID
g_all <- p4 + p5 + p6 + p7 + p15 + p8 + p9 + p10 + p11 + p12 + p13 + p14

## CREATE LIST OF GRIDS
list_all <- list(p4 , p5 , p6 , p7 , p15 , p8 , p9 , p10 , p11 , p12 , p13 , p14)


## MINIMAL CODED-DATA FRAME ONLY CONTINUOUS CONSTRUCTS
df_coded <- df_raw %>% 
  filter(CONSTRUCT_TYPE == "NUMERIC") %>% 
  mutate(
    PID = as.factor(PID),
    SAMPLE = factor(SAMPLE),
    CONSTRUCT_TYPE = factor(CONSTRUCT_TYPE),
    POLE_LEFT  = factor(POLE_LEFT),
    POLE_RIGHT = factor(POLE_RIGHT),
    POLES = paste0(POLE_LEFT,"-",POLE_RIGHT),
    FIRST = factor(FIRST),
    SECOND = factor(SECOND),
    THIRD = factor(THIRD),
    CODE_FULL = factor(CODE_STANDARD),
    CODE = factor(paste0(FIRST,"(",SECOND,")")),
    RELFEXIVE = as.logical(REFLEXIVE),
    MATCH = as.logical(MATCH)) %>% 
  mutate(
    across(CAREBEAR_BARS:BAYES_RIDGES, .fns = as.numeric)) %>% 
  select(
    -(CODE_DH:CODE_STANDARD)
  )

## LONG DATAFRAME 
## row = one participant construct X element
df_codedElements <- df_coded %>%
  pivot_longer(
    cols = CAREBEAR_BARS:BAYES_RIDGES,
    names_to ="ELEMENT") %>% 
  mutate(
    value=as.numeric(value),
    POLES = factor(POLES),
    ELEMENT = factor(ELEMENT, levels=stimuli)
  )


## CREATE DF FOR EFA 
## need constructs as columns 
df_eda <- df_codedElements |> 
  pivot_wider(
    names_from=CODE,
    values_from=value
  )
write_csv(df_eda, file = "data/NUMERIC_CONSTRUCTS_WIDE.csv")

```







# PARTICIPANT LEVEL


#### Construct Correlations (RAW)

```{r construct-correlations-example}

constructCor(p4)
elementCor(p4, method="pearson")


(c <- constructCor(p4, trim=50, index=FALSE, method="pearson"))

## todo amy fix plot
ggcorrplot(c, show.diag = TRUE, hc.order = FALSE, lab = TRUE, lab_size=0.2,
    type = "lower")

```



## Construct Dendrograms
```{r construct-clustering-dendrograms}

## PRINT CLUSTER FOR EACH PARTICIPANT
i=1
for (l in list_all){
  title = names[i]

  # # calculate cluster analysis
  # # https://docs.openrepgrid.org/articles/web/clustering.html
  cluster(l, along = 1, #1=constructs, 2 = elements, 0 = both (default)
        dmethod =  "euclidean",#distance measure TODO evaluate diff options    
        cmethod="ward.D", #agglomeration method TODO evaluate diff options
        align = TRUE, #align b4 clustering? reverses constructs if necessary to yield maximal simmilarity
        cex = 1, lab.cex = 1, main = title)  
  i=i+1
}
```

## Element Dendrograms
```{r element-clustering-dendrograms}

## PRINT CLUSTER FOR EACH PARTICIPANT
i=1
for (l in list_all){
  title = names[i]

  # # calculate cluster analysis
  # # https://docs.openrepgrid.org/articles/web/clustering.html
  cluster(l, along = 2, #1=constructs, 2 = elements, 0 = both (default)
        dmethod =  "euclidean",#distance measure TODO evaluate diff options    
        cmethod="ward.D", #agglomeration method TODO evaluate diff options
        align = TRUE, #align b4 clustering? reverses constructs if necessary to yield maximal simmilarity
        cex = 1, lab.cex = 1, main = title)  
  i=i+1
}
```



## Bertin Cluster Plots
```{r clustering-bertin}

## PRINT BERTIN CLUSTER MAP  FOR EACH PARTICIPANT
 i=1
for (l in list_all){
 
title = names[i]

  # https://docs.openrepgrid.org/articles/web/visualization-bertin.html
bertinCluster(l, along =1, #1=constructs, 2 = elements, 0 = both (default)
        dmethod =  "euclidean",#distance measure TODO evaluate diff options
        cmethod="ward.D", #agglomeration method TODO evaluate diff options
        align = TRUE, #align b4 clustering? reverses constructs if necessary to yield maximal simmilarity
        type = "rectangle",
        cex = 1, lab.cex = 1,
        trim=50, draw.axis = TRUE)
  op <- par(fig = c(0,1,0.1,1), mai=c(0,0,0.2,0), cex.main=0.85, adj=0, new = TRUE)
  title(title)

  i=i+1
}


## TODO WRITE SIMPLE BERTIN LOOP 
bertin(p4)


```






## PCA BIPLOTS

```{r biplot}

## PRINT PCA BIPLOT for each participant
i=1
for (l in list_all){
  title = names[i]
  
  # https://docs.openrepgrid.org/articles/web/visualization-biplot.html
  
  biplot2d(l, 
           dim = c(2,1),
           zoom = 1,
      
           ## construct s
           c.lines = TRUE,
           col.c.lines= gray(0.9),
           c.label.cex = 0.5,
           c.labels.inside = FALSE,
           c.label.col = "blue",
           
           ## elements
           # rect.margins = c(2,2),
           e.point.col = "red",
           e.label.col = "red",
           e.label.cex = 0.5, #element label size
           
           
           ## size and margins 
           mai = c(0.2,1.5,.2,1.5),
           unity=TRUE, #just makes it neater
           scale.e = 0.75, 
          
           )
  op <- par(# fig = c(0,1,0.5,1), 
           cex.main = 0.75, #title size
           new = TRUE)
  title(title)
  i=i+1
}

  
  
```

# WIP GROUP LEVEL
 
## COMPARE GROUPS - DENDROGRAM CONSTRUCTS

```{r group_dendrogram}


 cluster(g_researchers, along = 1, #1=constructs, 2 = elements, 0 = both (default)
        trim=100,
         dmethod =  "euclidean",#distance measure TODO evaluate diff options    
        cmethod="ward.D", #agglomeration method TODO evaluate diff options
        align = TRUE, #align b4 clustering? reverses constructs if necessary to yield maximal simmilarity
        cex = 1, lab.cex = 1, main = title)  

cluster(g_designers, along = 1, #1=constructs, 2 = elements, 0 = both (default)
       trim=100,
         dmethod =  "euclidean",#distance measure TODO evaluate diff options    
        cmethod="ward.D", #agglomeration method TODO evaluate diff options
        align = TRUE, #align b4 clustering? reverses constructs if necessary to yield maximal simmilarity
        cex = 1, lab.cex = 1, main = title)

```
 
## COMPARE GROUPS - DENDROGRAM ELEMENTS

```{r group_dendrogram}


 cluster(g_researchers, along = 2, #1=constructs, 2 = elements, 0 = both (default)
        trim=100,
         dmethod =  "euclidean",#distance measure TODO evaluate diff options    
        cmethod="ward.D", #agglomeration method TODO evaluate diff options
        align = TRUE, #align b4 clustering? reverses constructs if necessary to yield maximal simmilarity
        cex = 1, lab.cex = 1, main = "RESEARCHERS")  

cluster(g_designers, along = 2, #1=constructs, 2 = elements, 0 = both (default)
       trim=100,
         dmethod =  "euclidean",#distance measure TODO evaluate diff options    
        cmethod="ward.D", #agglomeration method TODO evaluate diff options
        align = TRUE, #align b4 clustering? reverses constructs if necessary to yield maximal simmilarity
        cex = 1, lab.cex = 1, main = "DESIGNERS")

```
 
 
## COMPARE GROUPS — PCA/BIPLOTS

```{r biplot-comparison}


  ## RESEARCHER BIPLOT
  title = "RESEARCHERS"
  print(title)
  biplot2d(g_researchers,
           dim = c(2,1),
           zoom = 1,
      
           ## construct s
           c.lines = TRUE,
           col.c.lines= gray(0.9),
           c.label.cex = 0.5,
           c.labels.inside = FALSE,
           c.label.col = "blue",
           
           ## elements
           # rect.margins = c(2,2),
           e.point.col = "red",
           e.label.col = "red",
           e.label.cex = 0.5, #element label size
           
           
           ## size and margins 
           mai = c(0.2,1.5,.2,1.5),
           unity=TRUE, #just makes it neater
           scale.e = 0.75, 
          
           )
  op <- par(# fig = c(0,1,0.5,1), 
           cex.main = 0.75, #title size
           new = TRUE)
  title(title)
  
  
  ## DESIGNER BIPLOT
  title = "DESIGNERS"
  print(title)
  biplot2d(g_designers,
           dim = c(2,1),
           zoom = 1,
      
           ## construct s
           c.lines = TRUE,
           col.c.lines= gray(0.9),
           c.label.cex = 0.5,
           c.labels.inside = FALSE,
           c.label.col = "blue",
           
           ## elements
           # rect.margins = c(2,2),
           e.point.col = "red",
           e.label.col = "red",
           e.label.cex = 0.5, #element label size
           
           
           ## size and margins 
           mai = c(0.2,1.5,.2,1.5), #margins 
           unity=TRUE, #just makes it neater
           scale.e = 0.75, 
          
           )
  op <- par(# fig = c(0,1,0.5,1), 
           cex.main = 0.75, #title size
           new = TRUE)
  title(title)


```

# ARF WIP

### WIP PCA — CONSTRUCTS 
```{r pca}


###### OPEN REP GRID APPROACH
constructPca(p15, nfactors = 2, trim=50, rotate="varimax",method="pearson")

###### VERSION psych::principal() 
## constructPca() is equivalent to this
corr <- constructCor(p15)

(p <- principal(corr, nfactors = 2, rotate="varimax", cor = "cor")) 
print(p)## PREFERRED OUTPUT! 


############ ?? not really sure if this is element or construct?
###### VERSION base::prcomp() 
### 1. CREATE TRANSPOSED DF FOR PCA ON CONSTRUCTS
df <- df_coded %>% 
  filter(PID=="P15") %>%
  select(CAREBEAR_BARS:BAYES_RIDGES, POLES) 
poles <- df$POLES # save construct names
#transpose
df <- t(df) %>% as_tibble()
colnames(df) = poles
#drop last row
df <- df[1:length(stimuli),]  # %>% slice(1:(n() - 1))
df <- df %>% mutate_all(as.numeric)
df <- df %>% mutate(element = factor(stimuli))
dpca <- df %>% select(where(is.numeric)) #get just the numeric cols 

### 2. RUN PCA ON DT 
pca <- prcomp(dpca, scale = TRUE )
summary(pca)
# data plot
autoplot(pca, data = df, color = "element", label=TRUE, label.size=5) + theme_minimal()
# biplot
biplot(pca)
# scree plot
plot(pca, type="lines")

```

### WIP AMY
more work here to explore clustering methods avail in 
https://www.datanovia.com/en/blog/cluster-analysis-in-r-simplified-and-enhanced/
https://www.sthda.com/english/wiki/wiki.php?id_contents=7851#visualize-supplementary-quantitative-variables


### WIP PCA ELEMENTS
```{r}


```


# ALL PARTICIPANTS

### Code Frequency table
```{r code_table}



## TABLE AT FIRST
crosstab(data = df_codedElements, rowvar = FIRST, colvar = SAMPLE, type = "percent")   # or "prop.col", 


## DATAFRAME
df <- df_codedElements %>% 
  select(FIRST,SECOND,THIRD,POLES,CODE_FULL,ELEMENT,SAMPLE,PID) 

## TWO LEVEL TABLE 
# one row per participant element X code
table_df <- df %>%
  count(FIRST, SECOND, SAMPLE) %>%
  pivot_wider(names_from = SAMPLE, values_from = n, values_fill = 0) %>%
  arrange(FIRST, SECOND) %>%
  group_by(FIRST) %>%
  mutate(FIRST = if_else(row_number() == 1, FIRST, ""),
         DESIGNER=DESIGNER/10,
         RESEARCHER=RESEARCHER/10
         ) %>%
  ungroup()
table_df %>% gt()


## THREE LEVEL TABLE
table_df <- df %>%
  count(FIRST, SECOND, THIRD, SAMPLE) %>%
  pivot_wider(
    names_from = SAMPLE,
    values_from = n,
    values_fill = 0
  ) %>%
  arrange(FIRST, SECOND, THIRD) %>%
  group_by(FIRST, SECOND) %>%
  mutate(
    THIRD = as.character(THIRD),
    SECOND = if_else(row_number() == 1, SECOND, ""),
    FIRST = if_else(row_number() == 1, FIRST, ""),
    DESIGNER=DESIGNER/10,
    RESEARCHER=RESEARCHER/10
  ) %>%
  ungroup()
table_df %>% gt()

## CONSTRUCT  LEVEL TABLE
table_df <- df %>%
  group_by(FIRST, SECOND, THIRD, SAMPLE) %>%
  summarise(POLES_values = paste(unique(POLES), collapse = ","), .groups = "drop") %>%
  pivot_wider(
    names_from = SAMPLE,
    values_from = POLES_values,
    values_fill = ""
  ) %>%
  arrange(FIRST, SECOND, THIRD) %>%
  group_by(FIRST, SECOND) %>%
  mutate(
    THIRD = as.character(THIRD),
    SECOND = if_else(row_number() == 1, SECOND, ""),
    FIRST = if_else(row_number() == 1, FIRST, "")
  ) %>%
  ungroup()
table_df %>% gt()






###### CODE LEVEL TO XLS
table_df <- df %>%
  group_by(FIRST, SECOND, THIRD, SAMPLE) %>%
  summarise(POLES_values = paste(unique(POLES), collapse = "\n"), .groups = "drop") %>%
  pivot_wider(
    names_from = SAMPLE,
    values_from = POLES_values,
    values_fill = ""
  ) %>%
  arrange(FIRST, SECOND, THIRD) %>%
  group_by(FIRST, SECOND) %>%
  mutate(
    THIRD = as.character(THIRD),
    SECOND = if_else(row_number() == 1, SECOND, ""),
    FIRST = if_else(row_number() == 1, FIRST, "")
  ) %>%
  ungroup()
# table_df
# knitr::kable(table_df)
# library(gt)
# table_df %>% gt()

write.xlsx(table_df, file = "table.xlsx", colNames=TRUE, asTable = TRUE)

```




## !! WIP LMER
```{r}

# df <- df_codedElements %>% 
#   select(
#     value, ELEMENT,CODE,POLES,PID,SAMPLE
#   )
# 
# 
# 
# m0 <- lmer(value ~ (1|PID),  data = df )
# summary(m0)
# 
# levels(df$ELEMENT)
# m1 <- lmer(value ~ ELEMENT*CODE + SAMPLE + (1|PID), data = df)
# summary(m1)
# plot_model(m1,type="pred", terms=c("CODE"))

```




# FUTURE AMY TODO

## Conflicts 
```{r}

## TODO WTAF is measured as 'conflict'? see 
# https://docs.openrepgrid.org/articles/web/measures-conflict.html
#Bell, R. C. (2004). A new approach to measuring inconsistency or conflict in grids. Personal Construct Theory & Practice, 1, 53–59.
#Heider, F. (1946). Attitudes and cognitive organization. Journal of Psychology, 21, 107–112.

indexConflict3(p4)

```

## Implicative Dilema
```{r}
#https://docs.openrepgrid.org/articles/web/measures-implicative.html

# Implicative dilemmas are closely related to the notion of conflict. An implicative dilemma arises when a desired change on one construct is associated with an undesired implication on another construct. E. g. a timid subject may want to become more socially skilled but associates being socially skilled with different negative characteristics (selfish, insensitive etc.). Hence, he may anticipate that becoming less timid will also make him more selfish (cf. Winter, 1982). 

i <- indexDilemma(p15, self=, ideal=10)
## TODO really actually figure out 1. if this is useful and 2. what it is doing. 3. how to define the self (vs) ideal self and align poles
plot(i)


```





# SCRATCH 
## Create Grid from dataframe
```{r}

# # CREATE a custom grid from the coded constructs dataframe
# 
# ######## FILTER MASTER DATAFRAME 
# d <- df %>% 
#   filter(
#       PID=="P15",
#       CONSTRUCT_TYPE=="NUMERIC"
#       ) %>% 
#   mutate_at(vars(CAREBEAR_BARS:BAYES_RIDGES), as.numeric) %>% 
#   mutate(
#     COUPLED = paste0(POLE_LEFT,"-",POLE_RIGHT),
#     CONSTRUCT = paste0(FIRST,"(",SECOND,")")
#   ) %>% select (
#     POLE_LEFT, POLE_RIGHT,
#     COUPLED,
#     CONSTRUCT,
#     CAREBEAR_BARS:BAYES_RIDGES)
#   # ) %>% column_to_rownames(var = "CONSTRUCT")
#   # ) %>% column_to_rownames(var = "CODE_STANDARD")
# ########### 
# 
# ## elements
# e <- d %>% select(-(POLE_LEFT:CONSTRUCT)) %>% colnames()
# # e <- c("care-bear","diamond-lady","bullets","heatmap","taxes",
#        # "penguins","physics-matplotlib","interaction","slope-interaction","bayesian")
# ## construct left pole
# l <- d %>% pull(POLE_LEFT)
# ## construct right pole
# r <- d %>% pull(POLE_RIGHT)
# ## construct code
# c <- d %>% pull(CONSTRUCT)
# 
# ## ratings
# ## have to unravel dataframe by row; unlist goes by column, 
# ## so instead, first transpose, then use 
# s <- c(t(d %>% select(CAREBEAR_BARS:BAYES_RIDGES)))
# 
# ## ASSEMBLE NEW REPGRID OBJECT
# ## args 
# args <- list(
#   name = e,
#   l.name = c,
#   # r.name = r,
#   coupled =F,
#   scores = s
#   ) 
# t15 <- makeRepgrid(args)
# t15 <- setScale(t15, 1, 5)
# t15
# 
# 
# g_double <- t15+t15

```



#### Construct Description (RAW)

```{r describe-constructs-example}

statsConstructs(p15,trim=50)

## ARF TODO reformat as df to get ridgeplot of histograms w/ constructs as rows?
```




#### Construct Correlations (RAW)

```{r construct-correlations-example}
constructCor(p15)


```





#### Describe Elements
```{r describe-elements-example}

# calculate descriptive statistics 
statsElements(p15)

```

#### Element Correlations
```{r correlations-elements-example}
elementCor(p15)
```



